{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "recsys_add new user.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mimJHiU-kWNY"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bw9anRhuFVGc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from zipfile import ZipFile\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import *"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "movielens_data_file_url = (\n",
        "    \"http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\"\n",
        ")\n",
        "movielens_zipped_file = keras.utils.get_file(\n",
        "    \"ml-latest-small.zip\", movielens_data_file_url, extract=False\n",
        ")\n",
        "keras_datasets_path = Path(movielens_zipped_file).parents[0]\n",
        "movielens_dir = keras_datasets_path / \"ml-latest-small\"\n",
        "\n",
        "# Only extract the data the first time the script is run.\n",
        "if not movielens_dir.exists():\n",
        "    with ZipFile(movielens_zipped_file, \"r\") as zip:\n",
        "        # Extract files\n",
        "        print(\"Extracting all the files now...\")\n",
        "        zip.extractall(path=keras_datasets_path)\n",
        "        print(\"Done!\")\n",
        "\n",
        "ratings_file = movielens_dir / \"ratings.csv\"\n",
        "df = pd.read_csv(ratings_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6JgKSU4FXhz",
        "outputId": "903bda61-2c30-4f81-9d28-fd005cf50b07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
            "983040/978202 [==============================] - 1s 1us/step\n",
            "991232/978202 [==============================] - 1s 1us/step\n",
            "Extracting all the files now...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tags_file = movielens_dir / \"movies.csv\"\n",
        "df_tags = pd.read_csv(tags_file)"
      ],
      "metadata": {
        "id": "0PHFPT2DG0vE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen = []\n",
        "\n",
        "for element in df_tags['genres']:\n",
        "  l = element.split('|')\n",
        "  for g in l:\n",
        "    if g not in gen:\n",
        "      gen.append(g)\n"
      ],
      "metadata": {
        "id": "96TXkU_XHRYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWlSGzvxHz8u",
        "outputId": "81554298-89d8-4cda-a4ce-eeef75426b3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Adventure',\n",
              " 'Animation',\n",
              " 'Children',\n",
              " 'Comedy',\n",
              " 'Fantasy',\n",
              " 'Romance',\n",
              " 'Drama',\n",
              " 'Action',\n",
              " 'Crime',\n",
              " 'Thriller',\n",
              " 'Horror',\n",
              " 'Mystery',\n",
              " 'Sci-Fi',\n",
              " 'War',\n",
              " 'Musical',\n",
              " 'Documentary',\n",
              " 'IMAX',\n",
              " 'Western',\n",
              " 'Film-Noir',\n",
              " '(no genres listed)']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorize(genr):\n",
        "  lab = np.zeros(len(gen))\n",
        "  l = genr.split('|')\n",
        "  for g in l:\n",
        "    lab[gen.index(g)] = 1\n",
        "  return lab\n",
        "    \n"
      ],
      "metadata": {
        "id": "Yt6rmOq5It1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_tags['vec'] = [vectorize(ele) for ele in df_tags['genres']]"
      ],
      "metadata": {
        "id": "qAfQZrdWFkaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_ids = df[\"userId\"].unique().tolist()\n",
        "user2user_encoded = {x: i for i, x in enumerate(user_ids)}\n",
        "userencoded2user = {i: x for i, x in enumerate(user_ids)}\n",
        "movie_ids = df[\"movieId\"].unique().tolist()\n",
        "movie2movie_encoded = {x: i for i, x in enumerate(movie_ids)}\n",
        "movie_encoded2movie = {i: x for i, x in enumerate(movie_ids)}"
      ],
      "metadata": {
        "id": "vfkcMGpFFzkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"user\"] = df[\"userId\"].map(user2user_encoded)\n",
        "df[\"movie\"] = df[\"movieId\"].map(movie2movie_encoded)\n",
        "num_users = len(user2user_encoded)\n",
        "num_movies = len(movie_encoded2movie)\n",
        "df[\"rating\"] = df[\"rating\"].values.astype(np.float32)\n",
        "\n",
        "min_rating = min(df[\"rating\"])\n",
        "max_rating = max(df[\"rating\"])\n",
        "\n",
        "print(\n",
        "    \"Number of users: {}, Number of Movies: {}, Min rating: {}, Max rating: {}\".format(\n",
        "        num_users, num_movies, min_rating, max_rating\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKje_En7GOS6",
        "outputId": "a86f2f1e-18dd-4ab7-8e2d-33f6bbf56fd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of users: 610, Number of Movies: 9724, Min rating: 0.5, Max rating: 5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.sample(frac=1, random_state=42)\n",
        "x = df[[\"user\", \"movie\"]].values\n",
        "# Normalize the targets between 0 and 1. Makes it easy to train.\n",
        "y = df[\"rating\"].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values\n",
        "\n",
        "movie_vec = df_tags['vec'].values\n",
        "movie_enc = [[movie_vec[i]] for i in x[:,1]]\n",
        "movie_enc = np.asarray(movie_enc)\n",
        "movie_enc = np.reshape(movie_enc,(movie_enc.shape[0], -1))"
      ],
      "metadata": {
        "id": "920wozDAGf_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_size = 50"
      ],
      "metadata": {
        "id": "HPABDhhvLXpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_embedding = layers.Embedding(\n",
        "            num_users,\n",
        "            embedding_size,\n",
        "            embeddings_initializer=\"he_normal\",\n",
        "            embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
        "        )\n",
        "\n",
        "inputs = keras.Input(shape=(1))\n",
        "emb = user_embedding(inputs)\n",
        "dense1 = Dense(25,activation = 'relu')(emb)\n",
        "dense2 = Dense(10,activation = 'sigmoid')(emb)\n",
        "dense2 = Flatten()(dense2)\n",
        "user_embedding_model = keras.Model(inputs, dense2)\n",
        "\n"
      ],
      "metadata": {
        "id": "gRjsYRzYLJB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movie_embedding = layers.Embedding(\n",
        "            num_movies,\n",
        "            embedding_size,\n",
        "            embeddings_initializer=\"he_normal\",\n",
        "            embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
        "        )\n",
        "\n",
        "inputs = keras.Input(shape=(1))\n",
        "emb = movie_embedding(inputs)\n",
        "dense1 = Dense(25,activation = 'relu')(emb)\n",
        "dense2 = Dense(10,activation = 'sigmoid')(emb)\n",
        "dense2 = Flatten()(dense2)\n",
        "movie_embedding_model = keras.Model(inputs, dense2)"
      ],
      "metadata": {
        "id": "GXmvTLCrMN2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "inputs = keras.Input(shape=(len(gen)))\n",
        "dense1 = Dense(25,activation = 'relu')(inputs)\n",
        "dense2 = Dense(10,activation = 'sigmoid')(dense1)\n",
        "genre_embedding_model = keras.Model(inputs, dense2)"
      ],
      "metadata": {
        "id": "gYDqEiVhMXVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "inputs = keras.Input(shape=(10))\n",
        "dense1 = Dense(7,activation = 'relu')(inputs)\n",
        "dense2 = Dense(5,activation = 'sigmoid')(dense1)\n",
        "sia_model = keras.Model(inputs, dense2)\n"
      ],
      "metadata": {
        "id": "_bZew2uBSqkt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def euclidean_distance(vectors):\n",
        "\t# unpack the vectors into separate lists\n",
        "\t(featsA, featsB) = vectors\n",
        "\t# compute the sum of squared distances between the vectors\n",
        "\tsumSquared = K.sum(K.square(featsA - featsB), axis=1,\n",
        "\t\tkeepdims=True)\n",
        "\t# return the euclidean distance between the vectors\n",
        "\treturn K.sqrt(K.maximum(sumSquared, K.epsilon()))"
      ],
      "metadata": {
        "id": "4EvIK6InTwbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.keras.backend as K\n",
        "import tensorflow as tf\n",
        "def contrastive_loss(y, preds, margin=1):\n",
        "\t# explicitly cast the true class label data type to the predicted\n",
        "\t# class label data type (otherwise we run the risk of having two\n",
        "\t# separate data types, causing TensorFlow to error out)\n",
        "\ty = tf.cast(y, preds.dtype)\n",
        "\t# calculate the contrastive loss between the true labels and\n",
        "\t# the predicted labels\n",
        "\tsquaredPreds = K.square(preds)\n",
        "\tsquaredMargin = K.square(K.maximum(margin - preds, 0))\n",
        "\tloss = K.mean(y * squaredPreds + (1 - y) * squaredMargin)\n",
        "\t# return the computed contrastive loss to the calling function\n",
        "\treturn loss"
      ],
      "metadata": {
        "id": "lUahEZfoT3yt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "input_m = keras.Input(shape=(1))\n",
        "input_g = keras.Input(shape=(20))\n",
        "me = movie_embedding_model(input_m)\n",
        "ge = genre_embedding_model(input_g)\n",
        "\n",
        "m_emb = sia_model(me)\n",
        "g_emb = sia_model(ge)\n",
        "\n",
        "distance = Lambda(euclidean_distance)([m_emb, g_emb])\n",
        "model = keras.Model(inputs=[input_m, input_g], outputs=distance)\n"
      ],
      "metadata": {
        "id": "G9MudQJuTbOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = tf.keras.optimizers.Adam(), loss = contrastive_loss)"
      ],
      "metadata": {
        "id": "e6oZdTSOUI1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "inputs_m = keras.Input(shape=(1))\n",
        "inputs_u = keras.Input(shape=(1))\n",
        "\n",
        "emb_m = movie_embedding_model(inputs_m)\n",
        "emb_u = user_embedding_model(inputs_u)\n",
        "\n",
        "d = tf.tensordot(emb_m, emb_u, 2)\n",
        "d = tf.nn.sigmoid(d)\n",
        "\n",
        "rec_model = keras.Model((inputs_m, inputs_u), d)"
      ],
      "metadata": {
        "id": "sioYlbGWZcnI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rec_model.compile(optimizer = tf.keras.optimizers.Adam(), loss = 'bce')"
      ],
      "metadata": {
        "id": "GO650_4_aBDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_indices = int(0.9 * df.shape[0])\n",
        "x_train, x_val, y_train, y_val = (\n",
        "    x[:train_indices],\n",
        "    x[train_indices:],\n",
        "    y[:train_indices],\n",
        "    y[train_indices:],\n",
        ")"
      ],
      "metadata": {
        "id": "NHpVJaQ-HF3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  x1 = x_train[batch1][:,1]\n",
        "  y1 = movie_enc[batch1]\n",
        "  x2 = x_train[batch1][:,1]\n",
        "  y2 = movie_enc[batch2]\n",
        "  x3 = np.concatenate((x1,x2))\n",
        "  y3 = np.concatenate((y1,y2), axis=0)\n",
        "  y = np.concatenate((np.ones(len(batch1)),np.ones(len(batch1))))"
      ],
      "metadata": {
        "id": "kykRaRYodSUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt = tf.keras.optimizers.Adam(1e-4)"
      ],
      "metadata": {
        "id": "Mx3RdKnzdTSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "  batch = np.arange(len(x_train))\n",
        "  np.random.shuffle(batch)\n",
        "  batch1=batch[:8]\n",
        "  batch2 = batch[10:18]\n",
        "  xt1 = x_train[batch1]\n",
        "  yt1 = y_train[batch1]\n",
        "\n",
        "  x1 = x_train[batch1][:,1]\n",
        "  y1 = movie_enc[batch1]\n",
        "  x2 = x_train[batch1][:,1]\n",
        "  y2 = movie_enc[batch2]\n",
        "  x3 = np.concatenate((x1,x2))\n",
        "  y3 = np.concatenate((y1,y2), axis=0)\n",
        "  y = np.concatenate((np.ones(len(batch1)),np.ones(len(batch1))))\n",
        "\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    out_rec = rec_model((xt1[:,1], xt1[:,0]))\n",
        "    loss_value_rec = tf.keras.losses.mean_squared_error(yt1, out_rec)\n",
        "    out_mod = model((x3[:1],y3))\n",
        "    loss_con = contrastive_loss(y,out_mod)\n",
        "    total_loss = loss_value_rec + loss_con\n",
        "    \n",
        "    grads = tape.gradient(total_loss, rec_model.trainable_weights)\n",
        "    opt.apply_gradients(zip(grads, [rec_model.trainable_weights]))\n",
        "    \n",
        "    grads = tape.gradient(total_loss, model.trainable_weights)\n",
        "    opt.apply_gradients(zip(grads, model.trainable_weights))  "
      ],
      "metadata": {
        "id": "0LfYCUUhaGtb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movie_df = pd.read_csv(movielens_dir / \"movies.csv\")\n",
        "\n",
        "# Let us get a user and see the top recommendations.\n",
        "user_id = df.userId.sample(1).iloc[0]\n",
        "movies_watched_by_user = df[df.userId == user_id]\n",
        "movies_not_watched = movie_df[\n",
        "    ~movie_df[\"movieId\"].isin(movies_watched_by_user.movieId.values)\n",
        "][\"movieId\"]\n",
        "movies_not_watched = list(\n",
        "    set(movies_not_watched).intersection(set(movie2movie_encoded.keys()))\n",
        ")\n",
        "movies_not_watched = [[movie2movie_encoded.get(x)] for x in movies_not_watched]\n",
        "user_encoder = user2user_encoded.get(user_id)\n",
        "user_movie_array = np.hstack(\n",
        "    ([[user_encoder]] * len(movies_not_watched), movies_not_watched)\n",
        ")\n",
        "ratings = rec_model.predict((user_movie_array[:,1],user_movie_array[:,0]) ).flatten()\n",
        "top_ratings_indices = ratings.argsort()[-10:][::-1]\n",
        "recommended_movie_ids = [\n",
        "    movie_encoded2movie.get(movies_not_watched[x][0]) for x in top_ratings_indices\n",
        "]\n",
        "\n",
        "print(\"Showing recommendations for user: {}\".format(user_id))\n",
        "print(\"====\" * 9)\n",
        "print(\"Movies with high ratings from user\")\n",
        "print(\"----\" * 8)\n",
        "top_movies_user = (\n",
        "    movies_watched_by_user.sort_values(by=\"rating\", ascending=False)\n",
        "    .head(5)\n",
        "    .movieId.values\n",
        ")\n",
        "movie_df_rows = movie_df[movie_df[\"movieId\"].isin(top_movies_user)]\n",
        "for row in movie_df_rows.itertuples():\n",
        "    print(row.title, \":\", row.genres)\n",
        "\n",
        "print(\"----\" * 8)\n",
        "print(\"Top 10 movie recommendations\")\n",
        "print(\"----\" * 8)\n",
        "recommended_movies = movie_df[movie_df[\"movieId\"].isin(recommended_movie_ids)]\n",
        "for row in recommended_movies.itertuples():\n",
        "    print(row.title, \":\", row.genres)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXQwnIhrTUFP",
        "outputId": "50bf1bbb-1392-464a-efb4-f69946b550b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Showing recommendations for user: 173\n",
            "====================================\n",
            "Movies with high ratings from user\n",
            "--------------------------------\n",
            "Sense and Sensibility (1995) : Drama|Romance\n",
            "Jeffrey (1995) : Comedy|Drama\n",
            "Forrest Gump (1994) : Comedy|Drama|Romance|War\n",
            "Four Weddings and a Funeral (1994) : Comedy|Romance\n",
            "Schindler's List (1993) : Drama|War\n",
            "--------------------------------\n",
            "Top 10 movie recommendations\n",
            "--------------------------------\n",
            "City Hall (1996) : Drama|Thriller\n",
            "Bottle Rocket (1996) : Adventure|Comedy|Crime|Romance\n",
            "Mr. Wrong (1996) : Comedy\n",
            "Unforgettable (1996) : Mystery|Sci-Fi|Thriller\n",
            "Happy Gilmore (1996) : Comedy\n",
            "Bridges of Madison County, The (1995) : Drama|Romance\n",
            "Nobody Loves Me (Keiner liebt mich) (1994) : Comedy|Drama\n",
            "Muppet Treasure Island (1996) : Adventure|Children|Comedy|Musical\n",
            "Catwalk (1996) : Documentary\n",
            "Die Hard: With a Vengeance (1995) : Action|Crime|Thriller\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "genres = np.zeros((1,20))\n",
        "movie_emb = movie_embedding_model(movie_df['movieId'].values)\n",
        "genre_emb = genre_embedding_model(genres)\n",
        "genre_emb = np.asarray([genre_emb for _ in range(movie_emb.shape[0])]).reshape((-1,10))\n",
        "movie_emb.shape\n",
        "rank = np.einsum('ij,ij->i',genre_emb,movie_emb)\n",
        "top_ratings_indices = rank.argsort()[-10:][::-1]\n",
        "recommended_movie_ids = [\n",
        "    movie_encoded2movie.get(movies_not_watched[x][0]) for x in top_ratings_indices\n",
        "]\n",
        "\n",
        "print(\"Showing recommendations for user: {}\".format(user_id))\n",
        "print(\"====\" * 9)\n",
        "\n",
        "print(\"Top 10 movie recommendations\")\n",
        "print(\"----\" * 8)\n",
        "recommended_movies = movie_df[movie_df[\"movieId\"].isin(recommended_movie_ids)]\n",
        "for row in recommended_movies.itertuples():\n",
        "    print(row.title, \":\", row.genres)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WA77sgCVhhxZ",
        "outputId": "7943e23a-b161-4408-e189-2192025f5678"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Showing recommendations for user: 173\n",
            "====================================\n",
            "Top 10 movie recommendations\n",
            "--------------------------------\n",
            "Smoke (1995) : Comedy|Drama\n",
            "Monty Python's Life of Brian (1979) : Comedy\n",
            "Air Bud (1997) : Children|Comedy\n",
            "Mouse Hunt (1997) : Children|Comedy\n",
            "House II: The Second Story (1987) : Comedy|Fantasy|Horror\n",
            "Married to the Mob (1988) : Comedy\n",
            "Diner (1982) : Comedy|Drama\n",
            "Sunshine (1999) : Drama\n",
            "Jason X (2002) : Horror|Sci-Fi|Thriller\n",
            "Start the Revolution Without Me (1970) : Comedy\n"
          ]
        }
      ]
    }
  ]
}